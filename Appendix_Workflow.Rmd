---
title: "ABCC_Group17_Appendix"
output:
  word_document:
date: "2025-12-08"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

This is an appendix containing code and commands used for workflow documentation of reproducing the bioinformatics analysis of the paper.

## [1] Downloading the data 
Retrieving the sequencing data from NCBI and downloading them onto the HPC. 
```{bash, eval=FALSE}
# Created a project directory 
mkdir /scratch/grp/msc_appbio/Group17_ABCC

# Create a directory for our raw sequencing data 
mkdir /scratch/grp/msc_appbio/Group17_ABCC/SRA_raw_data
cd /scratch/grp/msc_appbio/Group17_ABCC/SRA_raw_data

# Obtained the sequencing files from NCBI 
# SRA toolkit for prefetch 
module load sra-tools/3.0.3-gcc-13.2.0

# prefetch command for our sequencing data
prefetch SRR1166442 SRR1166443 SRR1166444 SRR1166445 SRR1166446 SRR1166447

# Create a directory for our reference genome
mkdir /scratch/grp/msc_appbio/Group17_ABCC/ref_genome
cd /scratch/grp/msc_appbio/Group17_ABCC/ref_genome

# Obtained the yeast reference genome from 
wget https://ftp.ncbi.nlm.nih.gov/genomes/all/GCF/000/146/045/GCF_000146045.2_ R64/GCF_000146045.2_R64_genomic.fna.gz 

# Unzipping the file 
gunzip GCF_000146045.2_R64_genomic.fna.gz
# Renaming the reference genome
mv GCF_000146045.2_R64_genomic.fna yeast_reference_genome.fna

# Created a directory to store our future scripts 
mkdir /scratch/grp/msc_appbio/Group17_ABCC/scripts
```

## [2] Converting the raw SRA to fastq format with sra tools
Fastq format conversion necessary for downstream analysis.
Submitted SBATCH sra_to_fastq.sh 
```{bash, eval=FALSE}
#!/bin/bash

#SBATCH --output=/scratch/grp/msc_appbio/Group17_ABCC/scripts/sra_job%j.out
#SBATCH --job-name=sra_to_fastq
#SBATCH --nodes=1
#SBATCH --ntasks=1
#SBATCH --time=01:00:00
#SBATCH --partition=msc_appbio

#Loading sra tools for conversion 
module load sra-tools/3.0.3-gcc-13.2.0

echo "Start of SRA conversion to fastq"

#Make a new directory for our output fastq
mkdir -p /scratch/grp/msc_appbio/Group17_ABCC/fastq_files 

#Set directory of where our raw sequences are
cd /scratch/grp/msc_appbio/Group17_ABCC/SRA_raw_data

#Command to convert 
fasterq-dump --split-files -O /scratch/grp/msc_appbio/Group17_ABCC/fastq_files *.sra

echo "End of fastq conversion"
```

## [3] QC of the sequences with fastqc
Performing quality control on these sequences to access the quality and to inform of any needed trimming.
Submitted SBATCH fastqc_job.sh
```{bash, eval=FALSE}
#!/bin/bash

#SBATCH --output=/scratch/grp/msc_appbio/Group17_ABBC/fastq_files/scripts/fastqc_job%j.out
#SBATCH --job-name=fastq_to_fastqc
#SBATCH --nodes=1
#SBATCH --ntasks=1
#SBATCH --time=01:00:00
#SBATCH --partition=msc_appbio

#Loading fastqc module
module load fastqc/0.11.9-gcc-13.2.0

echo "Start of fastqc"

#Set directory
cd /scratch/grp/msc_appbio/Group17_ABCC/fastq_files/

#Command to generate fastqc reports of all our fastq files
fastqc -o /scratch/grp/msc_appbio/Group17_ABCC/fastqc_report *.fastq

echo "End of fastqc"
```

## [4] Trimming with cutadapt
Fastqc reports identified adapters in the sequences which needed trimming.
Submitted SBATCH trimming.sh
```{bash, eval=FALSE}
#!/bin/bash

#SBATCH --output=/scratch/grp/msc_appbio/group17_ABCC/trimming_job_%j.out
#SBATCH --job-name=trimming
#SBATCH --time=01:00:00
#SBATCH --nodes=1

module load py-cutadapt/4.4-gcc-13.2.0-python-3.11.6

FASTQ_DIR=/scratch/grp/msc_appbio/Group17_ABCC/fastq_files

OUTPUT_DIR=/scratch/grp/msc_appbio/Group17_ABCC/trimmed
mkdir -p $OUTPUT_DIR

ADAPTER="AGATCGGAAGAGCACACGTCTGAACTCCAGTCA"

SAMPLES=(
SRR1166442
SRR1166443
SRR1166444
SRR1166445
SRR1166446
SRR1166447
)

for s in "${SAMPLES[@]}"; do
    if [[ ! -f "${FASTQ_DIR}/${s}.fastq" ]]; then
        echo "Warning: ${s}.fastq not found, skipping..."
        continue
    fi

    echo "Trimming adapters from $s.fastq..."
    cutadapt -a $ADAPTER -o ${OUTPUT_DIR}/${s}_trimmed.fastq ${FASTQ_DIR}/${s}.fastq --cores=4
    echo "Finished $s"
done

echo "All samples trimmed!"
```

## [5] QC on these trimmed reads
To access whether the adapters were successfully removed.
Submitted SBATCH trimmed_fastqc.sh
```{bash, eval=FALSE}
#!/bin/bash
#SBATCH --output=/scratch/grp/msc_appbio/group17_ABCC/trimmed_fastqc_%j.out
#SBATCH --job-name=trimmed_fastqc
#SBATCH --time=01:00:00
#SBATCH --nodes=1

module load fastqc/0.11.9-gcc-13.2.0

echo "start of fastqc"

cd /scratch/grp/msc_appbio/Group17_ABCC/trimmed

fastqc *_trimmed.fastq

echo "end of fastqc"
```

#### Performing a multiqc report.
Submitted SBATCH trimmed_multiqc.sh
```{bash, eval=FALSE}
#!/bin/bash
#SBATCH --output=/scratch/grp/msc_appbio/group17_ABCC/trimmed_multiqc_%j.out
#SBATCH --job-name=trimmed_multiqc
#SBATCH --time=01:00:00
#SBATCH --nodes=1

module load py-multiqc/1.15-gcc-13.2.0-python-3.11.6

echo "Running Multiqc on trimmed files"

TRIM_DIR=/scratch/grp/msc_appbio/group17_ABCC/trimmed

OUT_DIR=/scratch/grp/msc_appbio/group17_ABCC/trimmed_multiqc

mkdir -p /scratch/grp/msc_appbio/group17_ABCC/trimmed_multiqc

multiqc $TRIM_DIR -o $OUT_DIR

echo "MultiQC completed. Report saved to: $OUT_DIR"
```

------

## [6] Manually annotating and combining our custom genome

Locally downloaded N. crassa β-glucosidase gh1-1 CDS in gh1_1.fasta, N. crassa cellodextrin transporter cdt-1 in cdt-1.fasta and eGFP sequence.
Then SCP to HPC in /scratch/grp/msc_appbio/Group17_ABCC/ref_genome
The plasmid sequence pRS426-BT was not available online. 

### [6.1] Combine cdt1 and egfp together
Submitted SBATCH cdt1_egfp.sh
```{bash, eval=FALSE}
#!/bin/bash

#SBATCH --output=/scratch/grp/msc_appbio/Group17_ABCC/ref_genome/cdt1_egfp_job%j.out
#SBATCH --job-name=make_cdt1_egfp
#SBATCH --nodes=1
#SBATCH --ntasks=1
#SBATCH --time=01:00:00
#SBATCH --partition=msc_appbio

echo "Start of cdt1_egfp fusion"

cd /scratch/grp/msc_appbio/Group17_ABCC/ref_genome/

# Step 1: remove stop codon from cdt1_CDS
sed '1d' cdt-1_CDS.fasta | tr -d '\n' | sed 's/...$//' > cdt1_noSTOP.fasta

# Step 2: convert sequences to one-line format
grep -v "^>" cdt1_noSTOP.seq | tr -d '\n' > cdt1.fast
grep -v "^>" EGFP_CDS.fasta   | tr -d '\n' > egfp.fasta

# Step 3: create the fused cdt1_egfp FASTA
echo ">cdt1_egfp" > cdt1_egfp.fasta
cat cdt1.seq egfp.seq >> cdt1_egfp.fasta

echo "End of cdt1_egfp fusion"
```

### [6.2]  Manually combining the reference genome, gh1_1, cdt_1 + egfp into one fasta
Submitted SBATCH combined_genome.sh
```{bash, eval=FALSE}
#!/bin/bash

#SBATCH --output=/scratch/grp/msc_appbio/Group17_ABCC/ref_genome/combined_ref_job%j.out
#SBATCH --job-name=make_combined_ref
#SBATCH --nodes=1
#SBATCH --ntasks=1
#SBATCH --time=00:30:00
#SBATCH --partition=msc_appbio

echo "Start combining genome"

cd /scratch/grp/msc_appbio/Group17_ABCC/ref_genome

cat yeast_reference_genome.fna \
    gh1_1_CDS.fasta \
    cdt1_egfp.fasta \
    > custom_combined_genome.fasta

echo "Done combining genome"
```

### [6.3]  Checking the manually combined genome size 
Submitted SBATCH genome_size.sh 
```{bash, eval=FALSE}
#!/bin/bash
#SBATCH --output=/scratch/grp/msc_appbio/Group17_ABCC/ref_genome/genome_size_job%j.out
#SBATCH --job-name=genome_size
#SBATCH --nodes=1
#SBATCH --ntasks=1
#SBATCH --time=00:05:00
#SBATCH --partition=msc_appbio

echo "Checking genome size..."

cd /scratch/grp/msc_appbio/Group17_ABCC/ref_genome/

# Count total base pairs (no headers)
bp=$(grep -v "^>" custom_combined_genome.fasta | tr -d '\n' | wc -c)

echo "Total base pairs (bp): $bp"

# Convert to megabases (Mb) manually — printed in one line
echo "Genome size in Mb: $(echo "$bp / 1000000" | bc -l)"

echo "Done."
```


Total Genome size in Mb: 12160993

In the paper the total size of the custom reference genome was 12.17 Mb. This difference can be explained through the absence of the plasmid pRS426-BT.

### [6.4]  Manually annotate the genes 
Submitted SBATCHgtf_custom_genes.sh
```{bash, eval=FALSE}
#!/bin/bash
#SBATCH --output=/scratch/grp/msc_appbio/Group17_ABCC/ref_genome/gtf_custom_genes_job%j.out
#SBATCH --job-name=gtf_custom_genes
#SBATCH --nodes=1
#SBATCH --ntasks=1
#SBATCH --time=00:05:00
#SBATCH --partition=msc_appbio

echo "Adding custom genes to GTF..."

cd /scratch/grp/msc_appbio/Group17_ABCC/ref_genome/

# Get sequence lengths from FASTA
gh1_len=$(grep -A 100000 -m 1 ">gh1_1_CDS" custom_combined_genome.fasta | tail -n +2 | tr -d '\n' | wc -c)
cdt1_len=$(grep -A 100000 -m 1 ">cdt1_egfp" custom_combined_genome.fasta | tail -n +2 | tr -d '\n' | wc -c)

echo "gh1_1_CDS length (bp): $gh1_len"
echo "cdt1_egfp length (bp): $cdt1_len"

cat <<EOF >> gene_annotation_yeast.gtf
gh1_1_CDS       custom  gene    1       $gh1_len        .       +       .           gene_id "gh1_1_CDS";
gh1_1_CDS       custom  transcript      1       $gh1_len        .       +           .       gene_id "gh1_1_CDS"; transcript_id "gh1_1_CDS.t1";
gh1_1_CDS       custom  exon    1       $gh1_len        .       +       .           gene_id "gh1_1_CDS"; transcript_id "gh1_1_CDS.t1"; exon_number "1";

cdt1_egfp       custom  gene    1       $cdt1_len       .       +       .           gene_id "cdt1_egfp";
cdt1_egfp       custom  transcript      1       $cdt1_len       .       +           .       gene_id "cdt1_egfp"; transcript_id "cdt1_egfp.t1";
cdt1_egfp       custom  exon    1       $cdt1_len       .       +       .           gene_id "cdt1_egfp"; transcript_id "cdt1_egfp.t1"; exon_number "1";
EOF

echo "Custom genes successfully added to gtf."
```

------

## [7] Indexing with STAR
Indexing the custom_combined_genome.fasta to the custom_combined_annotation.gtf.
Submitted SBATCH indexing.sh
```{bash, eval=FALSE}
#!/bin/bash

#SBATCH --job-name=star_index_custom
#SBATCH --output=/scratch/grp/msc_appbio/Group17_ABCC/scripts/index_custom_%j.out
#SBATCH --time=03:00:00
#SBATCH --nodes=1
#SBATCH --ntasks=4
#SBATCH --partition=msc_appbio

module load star/2.7.10b-gcc-13.2.0

#Define our directories
indexdir=/scratch/grp/msc_appbio/Group17_ABCC/star_index
FASTA=/scratch/grp/msc_appbio/Group17_ABCC/ref_genome/custom_combined_genome.fasta
GTF=/scratch/grp/msc_appbio/Group17_ABCC/ref_genome/custom_combined_annotation.gtf

# Create a new directory for the output
mkdir -p $indexdir

echo "Start of star indexing"

STAR \
    --runMode genomeGenerate \
    --runThreadN 4 \
    --genomeDir $indexdir \
    --genomeFastaFiles $FASTA \
    --sjdbGTFfile $GTF \
    --sjdbOverhang 49
# Overhang of 49bp

echo "End of star indexing"
```

------

## [8] Alignment with STAR
Further cleaning of the trimmed reads were needed then an alignment was performed with the custom indexed genome.
Submitted SBATCH alignment.sh
```{bash, eval=FALSE}
#!/bin/bash

#SBATCH --output=/scratch/grp/msc_appbio/Group17_ABCC/scripts/star_clean_align_%j.out
#SBATCH --time=08:00:00
#SBATCH --nodes=1
#SBATCH --ntasks=4
#SBATCH --partition=msc_appbio

#Loading modules 
module load seqtk/1.4-gcc-13.2.0 #For cleaning the trimmed files
module load star/2.7.10b-gcc-13.2.0 #For our alignment
module load samtools/1.17-gcc-13.2.0-python-3.11.6 #For generating the BAM files

# Directories
trim_dir=/scratch/grp/msc_appbio/Group17_ABCC/trimmed
clean_trim_dir=/scratch/grp/msc_appbio/Group17_ABCC/trimmed_cleaned
alignment_dir=/scratch/grp/msc_appbio/Group17_ABCC/alignment_star
index_dir=/scratch/grp/msc_appbio/Group17_ABCC/star_index

#Making new directories
mkdir -p $clean_trim_dir
mkdir -p $alignment_dir

echo "Start of cleaning the trimmed and alignment"

# Loop for all 6 files 
for f in $trim_dir/*_trimmed.fastq; do
    sample=$(basename $f _trimmed.fastq)

    # 1. Clean the trimmed reads
    # Removes empty spacing - reads shorter than 1bp
    # Necessary for error prevention for alignment
    clean_FASTQ=$clean_trim_dir/${sample}_trimmed_clean.fastq
    echo "Cleaning $f "
    seqtk seq -L 1 $f > $clean_FASTQ

    # 2. Alignment of the cleaned trimmed reads
    # Output BAM files, necessary for featureCounts
    echo "Aligning $clean_FASTQ "
    STAR \
        --runThreadN 4 \
        --genomeDir $index_dir \
        --readFilesIn $clean_FASTQ \
        --outFileNamePrefix $alignment_dir/${sample}_ \
        --outSAMtype BAM SortedByCoordinate
done

echo "End of cleaning the trimmed and alignment"
```

Mapping results were assessed with the average uniquely mapped reads accounting to 87.93%, which is slightly higher to the reported 83.4% mapped of the paper.

SRR1166442
Number of input reads   | 40584434
Uniquely mapped reads % | 88.66%

SRR1166443
Number of input reads   | 44936907
Uniquely mapped reads % | 88.68%

SRR1166444
Number of input reads   | 34777833
Uniquely mapped reads % | 89.04%

SRR1166445
Number of input reads   | 45542623
Uniquely mapped reads % | 86.76%

SRR1166446
Number of input reads   | 38222169
Uniquely mapped reads % | 86.94%

SRR1166447
Number of input reads   | 34541421
Uniquely mapped reads % | 87.49%

------

## [9] Generating Count Data with featureCounts
Submitted SBATCH gene_counts.sh
```{bash, eval=FALSE}
#!/bin/bash
#SBATCH --output=/scratch/grp/msc_appbio/Group17_ABCC/alignment_star/featureCounts_job%j.out
#SBATCH --job-name=gene_counts
#SBATCH --nodes=1
#SBATCH --ntasks=1
#SBATCH --cpus-per-task=4
#SBATCH --time=01:00:00
#SBATCH --partition=msc_appbio

# Load Subread (featureCounts)
module load subread/2.0.2-gcc-13.2.0

echo "Starting gene counting with featureCounts"

# Move to alignment directory
cd /scratch/grp/msc_appbio/Group17_ABCC/alignment_star

# Run featureCounts correctly
featureCounts \
  -a /scratch/grp/msc_appbio/Group17_ABCC/ref_genome/custom_combined_annotation.gtf \
  -o gene_counts.txt \
  *.bam

echo "featureCounts gene counting finished."
```

------

## R
With the count table, gene_counts.txt was downloaded locally from the HPC to work with in R.

## [10] Differential Expression Analysis with DESeq2
```{r, message=FALSE, warning=FALSE}
# Load libraries
library(data.table)
library(DESeq2)
library(tidyverse)
library(dplyr)
library(ggplot2)
library(ggrepel)
```

```{r, message=FALSE, warning=FALSE}
# Set base directory 
setwd("C:/Users/sarah/OneDrive/Desktop/KCL/APCC/Group") 

# Import the data from local
gcdata <- fread("C:/Users/sarah/Downloads/gene_counts.txt", header = TRUE)

# Create a numeric matrix with the load counts in columns 7 to 12
counts <- as.matrix(gcdata[, 7:12, with=FALSE])
rownames(counts) <- gcdata$Geneid

# Define sample conditions
grown_condition <- factor(c("glucose", "glucose","glucose", "cellobiose", "cellobiose", "cellobiose"))
col_data<- data.frame(row.names = colnames(counts), grown_condition)

#Create the DESeq2 dataset 
data <- DESeqDataSetFromMatrix(
    countData = counts, 
    colData = col_data,
    design = ~ grown_condition 
)

# Run DESeq 
data <- DESeq(data)

# Contrast cellobiose vs glucose
results_deseq <- results(data, contrast = c("grown_condition", "cellobiose", "glucose"))

# Save as a csv
write.csv(results_deseq, file = "DESEQ_results.csv", row.names = FALSE)

# Normalised counts
norm_counts <- counts(data, normalized = TRUE)

# Save as a csv 
write.csv(norm_counts, file = "normalised_counts.csv", row.names = TRUE)
```

## [11] Significant Genes 
Calculate the number of differentially expressed genes.
```{r, message=FALSE, warning=FALSE}
# Saving the results_deseq as a data frame
results_df <- as.data.frame(results_deseq)
results_df <- na.omit(results_df) # remove NAs if there are

# Define thresholds
FDR_CUTOFF <- 0.001 # Define our cutoff for FDR
LOG2FC_CUTOFF <- 1.0 # Define our log2 2-fold change cutoff

# Add regulation label
results_df$regulation <- ifelse(
  results_df$padj < FDR_CUTOFF & results_df$log2FoldChange >= LOG2FC_CUTOFF, "Up",
  ifelse(results_df$padj < FDR_CUTOFF & results_df$log2FoldChange <= -LOG2FC_CUTOFF, "Down",
         "Not Significant")
)

# Significant genes (Up and Down combined)
sig_genes <- results_df[results_df$regulation != "Not Significant", ]
# Save as csv
write.csv(sig_genes, "Significant_Genes.csv", row.names = TRUE)

# Save Upregulated genes only as csv
up_genes <- results_df[results_df$regulation == "Up", ]
# Save as csv
write.csv(up_genes, "Upregulated_Genes.csv", row.names = TRUE)

# Save Downregulated genes only as csv
down_genes <- results_df[results_df$regulation == "Down", ]
# Save as csv
write.csv(down_genes, "Downregulated_Genes.csv", row.names = TRUE)

# Save complete annotated results table as csv
write.csv(results_df, "Full_DESeq2_Results_Annotated.csv", row.names = TRUE)

# Number of differentially expressed genes
num_sig <- nrow(sig_genes)
```

------ 

## [12] Volcano Plot
Plotting a volcano plot to visualise signifinicantly differentially expressed genes.
```{r, message=FALSE, warning=FALSE}
# Create our Y axis with -log10 padj
results_df$neglog10Padj <- -log10(results_df$padj)

# Creating our volcano plot
volcano_plot <- ggplot(results_df, 
                       aes(x = log2FoldChange, 
                           y = neglog10Padj, 
                           color = regulation)) +
  # Defining the points 
  geom_point(size = 1, alpha = 0.7) +
  scale_color_manual(values = c("Up" = "red", #significant 
                                "Down" = "red", 
                                "Not Significant" = "black")) +

  # Cut off lines
  geom_hline(yintercept = -log10(FDR_CUTOFF), # line for FDR cutoff
             linetype = "dashed", 
             color = "grey") +
  geom_vline(xintercept = c(-LOG2FC_CUTOFF, LOG2FC_CUTOFF), 
             linetype = "dashed", # line for log2 cutoff
             color = "grey") +
  
  # Defining labels
  labs(
    title = "Volcano Plot",
    subtitle = paste(num_sig, "Differentially Expressed Genes"),
    x = expression("log2 Fold Change (Cellobiose/Glucose) with DESeq"),
    y = expression("-log10 Adjusted P-value")
  ) +

  # Aesthetics
  theme_minimal() +
  theme(legend.title = element_blank())

print(volcano_plot)

# Save the plot
ggsave("Volcano_Plot.png", plot = volcano_plot, width = 7, height = 7, units = "in")
```
#load data into R
df <- read.table("C:/Users/ahuss/Downloads/gene_counts.txt",
                 header=TRUE, row.names=1)
#load RPKM data into R
RPKM <- read.csv("C:/Users/ahuss/Desktop/log2_rpkm_normalised.csv", header = TRUE)

#to view the data
view(RPKM)
View(df)

#load the package
library(ggplot2)

#summary of the dataframe - for boxplot, min, Q1, Q2, Q3, max, median, mean
summary(df)

#load the package
library(tidyverse)

#convert the dataframe into a long format for the values and grouping variables to compare distributions across groups
RPKM_long <- RPKM %>%
  pivot_longer(
    cols = -X,               
    names_to = "Sample",
    values_to = "log2_RPKM"
  )

#rename the column for clarity
RPKM_long <- RPKM_long %>% rename(Geneid = X)

# group damples into the two groups
RPKM_long <- RPKM_long %>%
  mutate(Group = case_when(
    Sample %in% c("SRR1166442_Aligned.sortedByCoord.out.bam",
                  "SRR1166443_Aligned.sortedByCoord.out.bam",
                  "SRR1166444_Aligned.sortedByCoord.out.bam ") ~ "Glucose-grown",
    Sample %in% c("SRR1166445_Aligned.sortedByCoord.out.bam",
                  "SRR1166446_Aligned.sortedByCoord.out.bam",
                  "SRR1166447_Aligned.sortedByCoord.out.bam") ~ "Cellobiose-grown"
  ))



#remove trailing spaces in sample names to ensure consistent string matching
RPKM_long <- RPKM_long %>%
  mutate(Sample = str_trim(Sample))

#separate the group columns
RPKM_long <- RPKM_long %>%
  mutate(Group = case_when(
    Sample %in% c("SRR1166442_Aligned.sortedByCoord.out.bam",
                  "SRR1166443_Aligned.sortedByCoord.out.bam",
                  "SRR1166444_Aligned.sortedByCoord.out.bam") ~ "Glucose-grown",
    Sample %in% c("SRR1166445_Aligned.sortedByCoord.out.bam",
                  "SRR1166446_Aligned.sortedByCoord.out.bam",
                  "SRR1166447_Aligned.sortedByCoord.out.bam") ~ "Cellobiose-grown"
  ))


#plot the data in the boxplot
p <- ggplot(RPKM_long, aes(x = Sample, y = log2_RPKM, color = Group)) +
  geom_boxplot(outlier.shape = NA, coef = 0) +
  stat_boxplot(geom = "errorbar", width = 0.3, linewidth = 0.8) +
  scale_color_manual(values = c("Glucose-grown" = "blue",
                                "Cellobiose-grown" = "red")) +
  theme_bw() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  ggtitle("Boxplot of log2-RPKM for 6 Samples by Group")

#print the plot
p

#save the plot
ggsave("~/Desktop/ABCC_plot.png", plot = p, width = 10, height = 6, dpi = 300)

#create the hierarchical cluster plot
#select the columns
sample_cols <- c(
  "SRR1166442_Aligned.sortedByCoord.out.bam",
  "SRR1166443_Aligned.sortedByCoord.out.bam",
  "SRR1166444_Aligned.sortedByCoord.out.bam",
  "SRR1166445_Aligned.sortedByCoord.out.bam",
  "SRR1166446_Aligned.sortedByCoord.out.bam",
  "SRR1166447_Aligned.sortedByCoord.out.bam"
)

#install and load the heatmap packages
install.packages("pheatmap")
library(pheatmap)

#hierarchical clustering
#extract sample columns
expr_matrix <- RPKM[, sample_cols] 

#convert to matrix
expr_matrix <- as.matrix(expr_matrix)      

#ensure numeric
mode(expr_matrix) <- "numeric"           

#Remove zero-variance genes (rows)
expr_matrix <- expr_matrix[apply(expr_matrix, 1, sd) != 0, ]

#Scale each gene (row)
expr_scaled <- t(scale(t(expr_matrix)))

#calculate the distance matrix for clustering, describing the differences between samples
d <- dist(expr_t)

#take the matrix and perform the hierarchical clustering
hc <- hclust(d, method = "complete")

#plot the hierarchical clustering plot
plot(hc, main = "Hierarchical Clustering of 6 Samples")

#highlightes the two clusters and draw the rectngles around them
rect.hclust(hc, k = 2, border = "red")

#produce discrete clusters tp assign each observation to the cluster
clusters <- cutree(hc, k = 2)

#count missing values 
sum(is.na(expr_matrix))

#count the infinite values in the dataset
sum(is.infinite(as.matrix(expr_matrix)))

#count any rows with zero variance before removing any rows
sum(apply(expr_matrix, 1, sd) == 0)

#remove rows with zero variance
expr_matrix <- expr_matrix[apply(expr_matrix, 1, sd) != 0, ]

#scale the rows
expr_scaled <- t(scale(t(expr_matrix)))

#load the package
library(pheatmap)

#extracts the colums corresponding to sample collumns
expr_matrix <- RPKM[, sample_cols]

#converts the extracted data into a matrix
expr_matrix <- as.matrix(expr_matrix)

#ensure the values are all numeric
mode(expr_matrix) <- "numeric"

# Remove zero-variance genes
expr_matrix <- expr_matrix[apply(expr_matrix, 1, sd) != 0, ]

# Row-scale
expr_scaled <- t(scale(t(expr_matrix)))

# Annotation
rownames(annotation_col) <- sample_cols

#annotate which cluster is for which sample
annotation_col <- data.frame(
  Condition = c(
    SRR1166442_Aligned.sortedByCoord.out.bam = "Glucose",
    SRR1166443_Aligned.sortedByCoord.out.bam = "Glucose",
    SRR1166444_Aligned.sortedByCoord.out.bam = "Glucose",
    SRR1166445_Aligned.sortedByCoord.out.bam = "Cellobiose",
    SRR1166446_Aligned.sortedByCoord.out.bam = "Cellobiose",
    SRR1166447_Aligned.sortedByCoord.out.bam = "Cellobiose"
  )
)

#to identify visually which sample is for which sequence
ann_colors <- list(
  Condition = c(Cellobiose = "blue", Glucose = "yellow")
)

# generate Heatmap, split samples into groups based on condition, with annotations and linking the hierarchical clustering with custom colour palletes
pheatmap(
  expr_scaled,
  column_split = annotation_col$Condition,
  cluster_rows = FALSE,
  cluster_cols = TRUE,
  annotation_col = annotation_col,
  annotation_colors = ann_colors,
  clustering_method = "complete",
  clustering_distance_cols = "correlation",
  show_rownames = FALSE,
  fontsize_col = 8,
  color = colorRampPalette(c("blue", "blue", "yellow"))(100),
  main = "Hierarchically clustered heatmap",
)

## [13] RPKM Calculation
Normalisation to Reads Per Kilobase of transcript per Million mapped reads (RPKM) needed for QC visualisations. 
```{r, message=FALSE, warning=FALSE}
gene_length_bp <- gcdata$Length # obtaining the length values
gene_length_kb <- gene_length_bp / 1000 # converting to kb 

# Normalising the length
raw_counts<- counts(data, normalized=FALSE)
# Total reads per library
total_counts <- colSums(raw_counts)

# Divide counts by gene length (kb)
rpkm <- sweep(raw_counts, 1, gene_length_kb, FUN="/")
# Divide by library totals (per million)
rpkm <- sweep(rpkm, 2, total_counts/1e6, FUN="/")

# log2 for visualization which address the "By Totals" normalisation method used in the original paper.
log2_rpkm <- log2(rpkm + 1)

# Create a csv
write.csv(log2_rpkm, file="log2_rpkm_normalised.csv", row.names=TRUE)
```

------

## [14] Functional Enrichment GO Analysis
```{r, message=FALSE, warning=FALSE}
library(clusterProfiler)
library(org.Sc.sgd.db)
```

```{r, message=FALSE, warning=FALSE}
# Create gene lists 
genes_all  <- rownames(sig_genes)
genes_up   <- rownames(up_genes)
genes_down <- rownames(down_genes)

# Enrich GO Biological Process
ego_all <- enrichGO(
  gene          = genes_all,
  OrgDb         = org.Sc.sgd.db,
  keyType       = "ORF",
  ont           = "BP",
  pAdjustMethod = "BH",
  qvalueCutoff  = 0.05
)

ego_up <- enrichGO(
  gene          = genes_up,
  OrgDb         = org.Sc.sgd.db,
  keyType       = "ORF",
  ont           = "BP",
  pAdjustMethod = "BH",
  qvalueCutoff  = 0.05
)

ego_down <- enrichGO(
  gene          = genes_down,
  OrgDb         = org.Sc.sgd.db,
  keyType       = "ORF",
  ont           = "BP",
  pAdjustMethod = "BH",
  qvalueCutoff  = 0.05
)

# Save results as csv 
write.csv(as.data.frame(ego_all),  "GO_BP_All.csv",   row.names = FALSE)
write.csv(as.data.frame(ego_up),   "GO_BP_Up.csv",    row.names = FALSE)
write.csv(as.data.frame(ego_down), "GO_BP_Down.csv",  row.names = FALSE)
```

## [15] making Function Enrichmend GO analysis table 

```{r, message=FALSE, warning=FALSE}
library(tidyr)
library(dplyr)

# UPREGULATED GO RESULTS ----
go_up_df <- as.data.frame(ego_up) %>%
  tidyr::separate(GeneRatio, into = c("k", "k_total"), sep = "/", convert = TRUE) %>%
  tidyr::separate(BgRatio,  into = c("f", "f_total"), sep = "/", convert = TRUE) %>%
  dplyr::select(Description, p.adjust, k, f, geneID) %>%
  dplyr::rename(
    `GO Term` = Description,
    `p-value (adjusted)` = p.adjust,
    `k (genes in cluster)` = k,
    `f (genes in category)` = f,
    `Genes in category from cluster` = geneID
  )

# DOWNREGULATED GO RESULTS ----
go_down_df <- as.data.frame(ego_down) %>%
  tidyr::separate(GeneRatio, into = c("k", "k_total"), sep = "/", convert = TRUE) %>%
  tidyr::separate(BgRatio, into = c("f", "f_total"), sep = "/", convert = TRUE) %>%
  dplyr::select(Description, p.adjust, k, f, geneID) %>%
  dplyr::rename(
    `GO Term` = Description,
    `p-value (adjusted)` = p.adjust,
    `k (genes in cluster)` = k,
    `f (genes in category)` = f,
    `Genes in category from cluster` = geneID
  )

# Save tables as csv
write.csv(go_up_df, "GO_BP_Up_Table.csv", row.names = FALSE)
write.csv(go_down_df, "GO_BP_Down_Table.csv", row.names = FALSE)
```

## [16] Creating a combined functional Enrichment GO table

```{r, message=FALSE, warning=FALSE}
# Header for UP genes
up_header <- as.data.frame(matrix("", nrow = 1, ncol = ncol(go_up_df)))
colnames(up_header) <- colnames(go_up_df)
up_header[1, 1] <- "GO terms for UPREGULATED genes"

# Header for DOWN genes
down_header <- as.data.frame(matrix("", nrow = 1, ncol = ncol(go_down_df)))
colnames(down_header) <- colnames(go_down_df)
down_header[1, 1] <- "GO terms for DOWNREGULATED genes"

# combining the tables 
go_combined <- rbind(
  up_header,
  go_up_df,
  down_header,
  go_down_df
)

# Save combined table as a csv
write.csv(go_combined, "GO_BP_Combined.csv", row.names = FALSE)
```






