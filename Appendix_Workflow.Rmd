---
title: "ABCC_Group17_Appendix"
output:
  word_document:
date: "2025-12-08"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

This is an appendix containing code and commands used for workflow documentation of reproducing the bioinformatics analysis of the paper.

## [1] Downloading the data 
Retrieving the sequencing data from NCBI and downloading them onto the HPC. 
```{bash, eval=FALSE}
# Created a project directory 
mkdir /scratch/grp/msc_appbio/Group17_ABCC

# Create a directory for our raw sequencing data 
mkdir /scratch/grp/msc_appbio/Group17_ABCC/SRA_raw_data
cd /scratch/grp/msc_appbio/Group17_ABCC/SRA_raw_data

# Obtained the sequencing files from NCBI 
# SRA toolkit for prefetch 
module load sra-tools/3.0.3-gcc-13.2.0

# prefetch command for our sequencing data
prefetch SRR1166442 SRR1166443 SRR1166444 SRR1166445 SRR1166446 SRR1166447

# Create a directory for our reference genome
mkdir /scratch/grp/msc_appbio/Group17_ABCC/ref_genome
cd /scratch/grp/msc_appbio/Group17_ABCC/ref_genome

# Obtained the yeast reference genome from 
wget https://ftp.ncbi.nlm.nih.gov/genomes/all/GCF/000/146/045/GCF_000146045.2_ R64/GCF_000146045.2_R64_genomic.fna.gz 

# Unzipping the file 
gunzip GCF_000146045.2_R64_genomic.fna.gz
# Renaming the reference genome
mv GCF_000146045.2_R64_genomic.fna yeast_reference_genome.fna

# Created a directory to store our future scripts 
mkdir /scratch/grp/msc_appbio/Group17_ABCC/scripts
```

## [2] Converting the raw SRA to fastq format with sra tools
Fastq format conversion necessary for downstream analysis.
Submitted SBATCH sra_to_fastq.sh 
```{bash, eval=FALSE}
#!/bin/bash

#SBATCH --output=/scratch/grp/msc_appbio/Group17_ABCC/scripts/sra_job%j.out
#SBATCH --job-name=sra_to_fastq
#SBATCH --nodes=1
#SBATCH --ntasks=1
#SBATCH --time=01:00:00
#SBATCH --partition=msc_appbio

module load sra-tools/3.0.3-gcc-13.2.0

echo "Start of SRA conversion to fastq"

mkdir -p /scratch/grp/msc_appbio/Group17_ABCC/fastq_files 

cd /scratch/grp/msc_appbio/Group17_ABCC/SRA_raw_data

fasterq-dump --split-files -O /scratch/grp/msc_appbio/Group17_ABCC/fastq_files *.sra

echo "End of fastq conversion"
```

## [3] QC of the sequences with fastqc
Performing quality control on these sequences to access the quality and to inform of any needed trimming.
Submitted SBATCH fastqc_job.sh
```{bash, eval=FALSE}
#!/bin/bash

#SBATCH --output=/scratch/grp/msc_appbio/Group17_ABBC/fastq_files/scripts/fastqc_job%j.out
#SBATCH --job-name=fastq_to_fastqc
#SBATCH --nodes=1
#SBATCH --ntasks=1
#SBATCH --time=01:00:00
#SBATCH --partition=msc_appbio

module load fastqc/0.11.9-gcc-13.2.0

echo "Start of fastqc"

cd /scratch/grp/msc_appbio/Group17_ABCC/fastq_files/

fastqc -o /scratch/grp/msc_appbio/Group17_ABCC/fastqc_report *.fastq

echo "End of fastqc"
```

## [4] Trimming with cutadapt
Fastqc reports identified adapters in the sequences which needed trimming.
Submitted SBATCH trimming.sh
```{bash, eval=FALSE}
#!/bin/bash

#SBATCH --output=/scratch/grp/msc_appbio/group17_ABCC/trimming_job_%j.out
#SBATCH --job-name=trimming
#SBATCH --time=01:00:00
#SBATCH --nodes=1

module load py-cutadapt/4.4-gcc-13.2.0-python-3.11.6

FASTQ_DIR=/scratch/grp/msc_appbio/Group17_ABCC/fastq_files

OUTPUT_DIR=/scratch/grp/msc_appbio/Group17_ABCC/trimmed
mkdir -p $OUTPUT_DIR

ADAPTER="AGATCGGAAGAGCACACGTCTGAACTCCAGTCA"

SAMPLES=(
SRR1166442
SRR1166443
SRR1166444
SRR1166445
SRR1166446
SRR1166447
)

for s in "${SAMPLES[@]}"; do
    if [[ ! -f "${FASTQ_DIR}/${s}.fastq" ]]; then
        echo "Warning: ${s}.fastq not found, skipping..."
        continue
    fi

    echo "Trimming adapters from $s.fastq..."
    cutadapt -a $ADAPTER -o ${OUTPUT_DIR}/${s}_trimmed.fastq ${FASTQ_DIR}/${s}.fastq --cores=4
    echo "Finished $s"
done

echo "All samples trimmed!"
```

## [5] QC on these trimmed reads

trimmed_fastqc.sh
```{bash, eval=FALSE}
#!/bin/bash
#SBATCH --output=/scratch/grp/msc_appbio/group17_ABCC/trimmed_fastqc_%j.out
#SBATCH --job-name=trimmed_fastqc
#SBATCH --time=01:00:00
#SBATCH --nodes=1

module load fastqc/0.11.9-gcc-13.2.0

echo "start of fastqc"

cd /scratch/grp/msc_appbio/Group17_ABCC/trimmed

fastqc *_trimmed.fastq

echo "end of fastqc"
```

Performing a multiqc report.
Submitted SBATCH trimmed_multiqc.sh
```{bash, eval=FALSE}
#!/bin/bash
#SBATCH --output=/scratch/grp/msc_appbio/group17_ABCC/trimmed_multiqc_%j.out
#SBATCH --job-name=trimmed_multiqc
#SBATCH --time=01:00:00
#SBATCH --nodes=1

module load py-multiqc/1.15-gcc-13.2.0-python-3.11.6

echo "Running Multiqc on trimmed files"

TRIM_DIR=/scratch/grp/msc_appbio/group17_ABCC/trimmed

OUT_DIR=/scratch/grp/msc_appbio/group17_ABCC/trimmed_multiqc

mkdir -p /scratch/grp/msc_appbio/group17_ABCC/trimmed_multiqc

multiqc $TRIM_DIR -o $OUT_DIR

echo "MultiQC completed. Report saved to: $OUT_DIR"
```

------

## Manually annotating and combining our custom genome

Locally downloaded N. crassa β-glucosidase gh1-1 CDS in gh1_1.fasta, N. crassa cellodextrin transporter cdt-1 in cdt-1.fasta and eGFP sequence.
Then SCP to HPC in /scratch/grp/msc_appbio/Group17_ABCC/ref_genome

## [6] Combine cdt1 and egfp together
Submitted SBATCH cdt1_egfp.sh
```{bash, eval=FALSE}
#!/bin/bash

#SBATCH --output=/scratch/grp/msc_appbio/Group17_ABCC/ref_genome/cdt1_egfp_job%j.out
#SBATCH --job-name=make_cdt1_egfp
#SBATCH --nodes=1
#SBATCH --ntasks=1
#SBATCH --time=01:00:00
#SBATCH --partition=msc_appbio

echo "Start of cdt1_egfp fusion"

cd /scratch/grp/msc_appbio/Group17_ABCC/ref_genome/

# Step 1: remove stop codon from cdt1_CDS
sed '1d' cdt-1_CDS.fasta | tr -d '\n' | sed 's/...$//' > cdt1_noSTOP.fasta

# Step 2: convert sequences to one-line format
grep -v "^>" cdt1_noSTOP.seq | tr -d '\n' > cdt1.fast
grep -v "^>" EGFP_CDS.fasta   | tr -d '\n' > egfp.fasta

# Step 3: create the fused cdt1_egfp FASTA
echo ">cdt1_egfp" > cdt1_egfp.fasta
cat cdt1.seq egfp.seq >> cdt1_egfp.fasta

echo "End of cdt1_egfp fusion"
```

## [7] Manually combining the reference genome, gh1_1, cdt_1 + egfp into one fasta
Submitted SBATCH combined_genome.sh
```{bash, eval=FALSE}
#!/bin/bash

#SBATCH --output=/scratch/grp/msc_appbio/Group17_ABCC/ref_genome/combined_ref_job%j.out
#SBATCH --job-name=make_combined_ref
#SBATCH --nodes=1
#SBATCH --ntasks=1
#SBATCH --time=00:30:00
#SBATCH --partition=msc_appbio

echo "Start combining genome"

cd /scratch/grp/msc_appbio/Group17_ABCC/ref_genome

cat yeast_reference_genome.fna \
    gh1_1_CDS.fasta \
    cdt1_egfp.fasta \
    > custom_combined_genome.fasta

echo "Done combining genome"
```

## [8] Checking the manually combined genome size 
Submitted SBATCH genome_size.sh 
```{bash, eval=FALSE}
#!/bin/bash
#SBATCH --output=/scratch/grp/msc_appbio/Group17_ABCC/ref_genome/genome_size_job%j.out
#SBATCH --job-name=genome_size
#SBATCH --nodes=1
#SBATCH --ntasks=1
#SBATCH --time=00:05:00
#SBATCH --partition=msc_appbio

echo "Checking genome size..."

cd /scratch/grp/msc_appbio/Group17_ABCC/ref_genome/

# Count total base pairs (no headers)
bp=$(grep -v "^>" combined_yeast_ref_genome.fasta | tr -d '\n' | wc -c)

echo "Total base pairs (bp): $bp"

# Convert to megabases (Mb) manually — printed in one line
echo "Genome size in Mb: $(echo "$bp / 1000000" | bc -l)"

echo "Done."
```

# [9] Manually annotate the genes 
Submitted SBATCHgtf_custom_genes.sh
```{bash, eval=FALSE}
#!/bin/bash
#SBATCH --output=/scratch/grp/msc_appbio/Group17_ABCC/ref_genome/gtf_custom_genes_job%j.out
#SBATCH --job-name=gtf_custom_genes
#SBATCH --nodes=1
#SBATCH --ntasks=1
#SBATCH --time=00:05:00
#SBATCH --partition=msc_appbio

echo "Adding custom genes to GTF..."

cd /scratch/grp/msc_appbio/Group17_ABCC/ref_genome/

# Get sequence lengths from FASTA
gh1_len=$(grep -A 100000 -m 1 ">gh1_1_CDS" custom_combined_genome.fasta | tail -n +2 | tr -d '\n' | wc -c)
cdt1_len=$(grep -A 100000 -m 1 ">cdt1_egfp" custom_combined_genome.fasta | tail -n +2 | tr -d '\n' | wc -c)

echo "gh1_1_CDS length (bp): $gh1_len"
echo "cdt1_egfp length (bp): $cdt1_len"

cat <<EOF >> gene_annotation_yeast.gtf
gh1_1_CDS       custom  gene    1       $gh1_len        .       +       .           gene_id "gh1_1_CDS";
gh1_1_CDS       custom  transcript      1       $gh1_len        .       +           .       gene_id "gh1_1_CDS"; transcript_id "gh1_1_CDS.t1";
gh1_1_CDS       custom  exon    1       $gh1_len        .       +       .           gene_id "gh1_1_CDS"; transcript_id "gh1_1_CDS.t1"; exon_number "1";

cdt1_egfp       custom  gene    1       $cdt1_len       .       +       .           gene_id "cdt1_egfp";
cdt1_egfp       custom  transcript      1       $cdt1_len       .       +           .       gene_id "cdt1_egfp"; transcript_id "cdt1_egfp.t1";
cdt1_egfp       custom  exon    1       $cdt1_len       .       +       .           gene_id "cdt1_egfp"; transcript_id "cdt1_egfp.t1"; exon_number "1";
EOF

echo "Custom genes successfully added to gtf."
```

------

## [10] Indexing with STAR
Indexing the custom_combined_genome.fasta to the custom_combined_annotation.gtf.
Submitted SBATCH indexing.sh
```{bash, eval=FALSE}
#!/bin/bash

#SBATCH --job-name=star_index_custom
#SBATCH --output=/scratch/grp/msc_appbio/Group17_ABCC/scripts/index_custom_%j.out
#SBATCH --time=03:00:00
#SBATCH --nodes=1
#SBATCH --ntasks=4
#SBATCH --partition=msc_appbio

module load star/2.7.10b-gcc-13.2.0

#Define our directories
indexdir=/scratch/grp/msc_appbio/Group17_ABCC/star_index
FASTA=/scratch/grp/msc_appbio/Group17_ABCC/ref_genome/custom_combined_genome.fasta
GTF=/scratch/grp/msc_appbio/Group17_ABCC/ref_genome/custom_combined_annotation.gtf

# Create a new directory for the output
mkdir -p $indexdir

echo "Start of star indexing"

STAR \
    --runMode genomeGenerate \
    --runThreadN 4 \
    --genomeDir $indexdir \
    --genomeFastaFiles $FASTA \
    --sjdbGTFfile $GTF \
    --sjdbOverhang 49
# Overhang of 49bp

echo "End of star indexing"
```

------

## [11] Alignment with STAR
Further cleaning of the trimmed reads were needed then an alignment was performed with the custom indexed genome.
Submitted SBATCH alignment.sh
```{bash, eval=FALSE}
#!/bin/bash

#SBATCH --output=/scratch/grp/msc_appbio/Group17_ABCC/scripts/star_clean_align_%j.out
#SBATCH --time=08:00:00
#SBATCH --nodes=1
#SBATCH --ntasks=4
#SBATCH --partition=msc_appbio

module load seqtk/1.4-gcc-13.2.0
module load star/2.7.10b-gcc-13.2.0
module load samtools/1.17-gcc-13.2.0-python-3.11.6

# Directories
trim_dir=/scratch/grp/msc_appbio/Group17_ABCC/trimmed
clean_trim_dir=/scratch/grp/msc_appbio/Group17_ABCC/trimmed_cleaned
alignment_dir=/scratch/grp/msc_appbio/Group17_ABCC/alignment_star
index_dir=/scratch/grp/msc_appbio/Group17_ABCC/star_index

mkdir -p $clean_trim_dir
mkdir -p $alignment_dir

echo "Start of cleaning the trimmed and alignment"

# Loop for all 6 files 
for f in $trim_dir/*_trimmed.fastq; do
    sample=$(basename $f _trimmed.fastq)

    # 1. Clean the trimmed reads
    clean_FASTQ=$clean_trim_dir/${sample}_trimmed_clean.fastq
    echo "Cleaning $f "
    seqtk seq -L 1 $f > $clean_FASTQ

    # 2. Alignment on the cleaned trimmed reads
    echo "Aligning $clean_FASTQ "
    STAR \
        --runThreadN 4 \
        --genomeDir $index_dir \
        --readFilesIn $clean_FASTQ \
        --outFileNamePrefix $alignment_dir/${sample}_ \
        --outSAMtype BAM SortedByCoordinate
done

echo "End of cleaning the trimmed and alignment"
```

------

## [12] Generating Count Data with featureCounts
gene_counts.sh
```{bash, eval=FALSE}
#!/bin/bash
#SBATCH --output=/scratch/grp/msc_appbio/Group17_ABCC/alignment_star/featureCounts_job%j.out
#SBATCH --job-name=gene_counts
#SBATCH --nodes=1
#SBATCH --ntasks=1
#SBATCH --cpus-per-task=4
#SBATCH --time=01:00:00
#SBATCH --partition=msc_appbio

# Load Subread (featureCounts)
module load subread/2.0.2-gcc-13.2.0

echo "Starting gene counting with featureCounts"

# Move to alignment directory
cd /scratch/grp/msc_appbio/Group17_ABCC/alignment_star

# Run featureCounts correctly
featureCounts \
  -a /scratch/grp/msc_appbio/Group17_ABCC/ref_genome/custom_combined_annotation.gtf \
  -o gene_counts.txt \
  *.bam

echo "featureCounts gene counting finished."
```

------
# R
With the count table, gene_counts.txt was downloaded locally from the HPC to work with in R.

## [13] Differential Expression Analysis with DESeq2

```{r, message=FALSE, warning=FALSE}
# Load libraries
library(data.table)
library(DESeq2)
library(tidyverse)
library(dplyr)
library(ggplot2)
library(ggrepel)
```

```{r}
# Set base directory 
setwd("C:/Users/sarah/OneDrive/Desktop/KCL/APCC/Group") 

# Import the data from local
gcdata <- fread("C:/Users/sarah/Downloads/gene_counts.txt", header = TRUE)

# Create a numeric matrix with the load counts in columns 7 to 12
counts <- as.matrix(gcdata[, 7:12, with=FALSE])
rownames(counts) <- gcdata$Geneid

# Define sample conditions
grown_condition <- factor(c("glucose", "glucose","glucose", "cellobiose", "cellobiose", "cellobiose"))
col_data<- data.frame(row.names = colnames(counts), grown_condition)

#Create the DESeq2 dataset 
data <- DESeqDataSetFromMatrix(
    countData = counts, 
    colData = col_data,
    design = ~ grown_condition 
)

# Run DESeq 
data <- DESeq(data)

# Contrast cellobiose vs glucose
results_deseq <- results(data, contrast = c("grown_condition", "cellobiose", "glucose"))

# Save as a csv
write.csv(results_deseq, file = "DESEQ_results.csv", row.names = FALSE)

# Normalised counts
norm_counts <- counts(data, normalized = TRUE)

# Save as a csv 
write.csv(norm_counts, file = "normalised_counts.csv", row.names = TRUE)
```

## [14] Significant Genes 
Calculate the number of differentially expressed genes.
```{r,}
# Saving the results_deseq as a data frame
results_df <- as.data.frame(results_deseq)
results_df <- na.omit(results_df) # remove NAs if there are

# Define thresholds
FDR_CUTOFF <- 0.001 # Define our cutoff for FDR
LOG2FC_CUTOFF <- 1.0 # Define our log2 2-fold change cutoff

# Add regulation label
results_df$regulation <- ifelse(
  results_df$padj < FDR_CUTOFF & results_df$log2FoldChange >= LOG2FC_CUTOFF, "Up",
  ifelse(results_df$padj < FDR_CUTOFF & results_df$log2FoldChange <= -LOG2FC_CUTOFF, "Down",
         "Not Significant")
)

# Significant genes (Up and Down combined)
sig_genes <- results_df[results_df$regulation != "Not Significant", ]
# Save as csv
write.csv(sig_genes, "Significant_Genes.csv", row.names = TRUE)

# Save Upregulated genes only as csv
up_genes <- results_df[results_df$regulation == "Up", ]
# Save as csv
write.csv(up_genes, "Upregulated_Genes.csv", row.names = TRUE)

# Save Downregulated genes only as csv
down_genes <- results_df[results_df$regulation == "Down", ]
# Save as csv
write.csv(down_genes, "Downregulated_Genes.csv", row.names = TRUE)

# Save complete annotated results table as csv
write.csv(results_df, "Full_DESeq2_Results_Annotated.csv", row.names = TRUE)

# Number of differentially expressed genes
num_sig <- nrow(sig_genes)
```

------ 

## [14] Volcano Plot
Plotting a volcano plot to visualise signifinicantly differential expressed genes.
```{r}
# Create our Y axis with -log10 padj
results_df$neglog10Padj <- -log10(results_df$padj)

# Creating our volcano plot
volcano_plot <- ggplot(results_df, 
                       aes(x = log2FoldChange, 
                           y = neglog10Padj, 
                           color = regulation)) +
  # Defining the points 
  geom_point(size = 1, alpha = 0.7) +
  scale_color_manual(values = c("Up" = "red", #significant 
                                "Down" = "red", 
                                "Not Significant" = "black")) +

  # Cut off lines
  geom_hline(yintercept = -log10(FDR_CUTOFF), # line for FDR cutoff
             linetype = "dashed", 
             color = "grey") +
  geom_vline(xintercept = c(-LOG2FC_CUTOFF, LOG2FC_CUTOFF), 
             linetype = "dashed", # line for log2 cutoff
             color = "grey") +
  
  # Defining labels
  labs(
    title = "Volcano Plot",
    subtitle = paste(num_sig, "Differentially Expressed Genes"),
    x = expression("log2 Fold Change (Cellobiose/Glucose) with DESeq"),
    y = expression("-log10 Adjusted P-value")
  ) +

  # Aesthetics
  theme_minimal() +
  theme(legend.title = element_blank())

print(volcano_plot)

# Save the plot
ggsave("Volcano_Plot.png", plot = volcano_plot, width = 7, height = 7, units = "in")
```

## [15] RPKM Calculation
Normalisation to Reads Per Kilobase of transcript per Million mapped reads (RPKM) needed for QC visualisations. 
```{r}
gene_length_bp <- gcdata$Length # obtaining the length values
gene_length_kb <- gene_length_bp / 1000 # converting to kb 

# Normalising the length
raw_counts<- counts(data, normalized=FALSE)
# Total reads per library
total_counts <- colSums(raw_counts)

# Divide counts by gene length (kb)
rpkm <- sweep(counts, 1, gene_length_kb, FUN="/")
# Divide by library totals (per million)
rpkm <- sweep(rpkm, 2, total_counts/1e6, FUN="/")

# log2 for visualization which address the "By Totals" normalisation method used in the original paper.
log2_rpkm <- log2(rpkm + 1)

# Create a csv
write.csv(log2_rpkm, file="log2_rpkm_normalised.csv", row.names=TRUE)
```

------

## [16] Functional Enrichment GO Analysis
```{r, message=FALSE, warning=FALSE}
library(clusterProfiler)
library(org.Sc.sgd.db)
library(enrichplot)
```

```{r}
# Create gene lists 
genes_all  <- rownames(sig_genes)
genes_up   <- rownames(up_genes)
genes_down <- rownames(down_genes)

# Enrich GO Biological Process
ego_all <- enrichGO(
  gene          = genes_all,
  OrgDb         = org.Sc.sgd.db,
  keyType       = "ORF",
  ont           = "BP",
  pAdjustMethod = "BH",
  qvalueCutoff  = 0.05
)

ego_up <- enrichGO(
  gene          = genes_up,
  OrgDb         = org.Sc.sgd.db,
  keyType       = "ORF",
  ont           = "BP",
  pAdjustMethod = "BH",
  qvalueCutoff  = 0.05
)

ego_down <- enrichGO(
  gene          = genes_down,
  OrgDb         = org.Sc.sgd.db,
  keyType       = "ORF",
  ont           = "BP",
  pAdjustMethod = "BH",
  qvalueCutoff  = 0.05
)

# Save results as csv 
write.csv(as.data.frame(ego_all),  "GO_BP_All.csv",   row.names = FALSE)
write.csv(as.data.frame(ego_up),   "GO_BP_Up.csv",    row.names = FALSE)
write.csv(as.data.frame(ego_down), "GO_BP_Down.csv",  row.names = FALSE)
```

## [17] making Function Enrichmend GO analysis table 

```{r, message=FALSE, warning=FALSE}
library(tidyr)
library(dplyr)

# UPREGULATED GO RESULTS ----
go_up_df <- as.data.frame(ego_up) %>%
  tidyr::separate(GeneRatio, into = c("k", "k_total"), sep = "/", convert = TRUE) %>%
  tidyr::separate(BgRatio,  into = c("f", "f_total"), sep = "/", convert = TRUE) %>%
  dplyr::select(Description, p.adjust, k, f, geneID) %>%
  dplyr::rename(
    `GO Term` = Description,
    `p-value (adjusted)` = p.adjust,
    `k (genes in cluster)` = k,
    `f (genes in category)` = f,
    `Genes in category from cluster` = geneID
  )

# DOWNREGULATED GO RESULTS ----
go_down_df <- as.data.frame(ego_down) %>%
  tidyr::separate(GeneRatio, into = c("k", "k_total"), sep = "/", convert = TRUE) %>%
  tidyr::separate(BgRatio, into = c("f", "f_total"), sep = "/", convert = TRUE) %>%
  dplyr::select(Description, p.adjust, k, f, geneID) %>%
  dplyr::rename(
    `GO Term` = Description,
    `p-value (adjusted)` = p.adjust,
    `k (genes in cluster)` = k,
    `f (genes in category)` = f,
    `Genes in category from cluster` = geneID
  )

# Save tables as csv
write.csv(go_up_df, "GO_BP_Up_Table.csv", row.names = FALSE)
write.csv(go_down_df, "GO_BP_Down_Table.csv", row.names = FALSE)
```

## [18] Creating a combined functional Enrichment GO table
```{r}
# Header for UP genes
up_header <- as.data.frame(matrix("", nrow = 1, ncol = ncol(go_up_df)))
colnames(up_header) <- colnames(go_up_df)
up_header[1, 1] <- "GO terms for UPREGULATED genes"

# Header for DOWN genes
down_header <- as.data.frame(matrix("", nrow = 1, ncol = ncol(go_down_df)))
colnames(down_header) <- colnames(go_down_df)
down_header[1, 1] <- "GO terms for DOWNREGULATED genes"

# combining the tables 
go_combined <- rbind(
  up_header,
  go_up_df,
  down_header,
  go_down_df
)

# Save combined table as a csv
write.csv(go_combined, "GO_BP_Combined.csv", row.names = FALSE)
```
