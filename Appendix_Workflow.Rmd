---
title: "ABCC_Group17_Appendix"
output: html_document
date: "2025-12-08"
---

This is an appendix containing code and commands used for workflow documentation of reproducing the bioinformatics analysis of the paper.

## Downloading the data 

```{bash}
# Created a project directory 
mkdir /scratch/grp/msc_appbio/Group17_ABCC

# Create a directory for our raw sequencing data 
mkdir /scratch/grp/msc_appbio/Group17_ABCC/SRA_raw_data

cd /scratch/grp/msc_appbio/Group17_ABCC/SRA_raw_data

# Obtained the sequencing files from NCBI 
# SRA toolkit for prefetch 
module load sra-tools/3.0.3-gcc-13.2.0

prefetch SRR1166442 SRR1166443 SRR1166444 SRR1166445 SRR1166446 SRR1166447


# Create a directory for our reference genome
mkdir /scratch/grp/msc_appbio/Group17_ABCC/ref_genome
cd /scratch/grp/msc_appbio/Group17_ABCC/ref_genome
# Obtained the yeast reference genome from 
wget https://ftp.ncbi.nlm.nih.gov/genomes/all/GCF/000/146/045/GCF_000146045.2_ R64/GCF_000146045.2_R64_genomic.fna.gz 
# Unzip 
gunzip GCF_000146045.2_R64_genomic.fna.gz
# Rename
mv GCF_000146045.2_R64_genomic.fna yeast_reference_genome.fna

# Created a directory to store our scripts
mkdir /scratch/grp/msc_appbio/Group17_ABCC/scripts

```

## Converting raw SRA to fastq format

sra_to_fastq.sh
```{bash}
#!/bin/bash

#SBATCH --output=/scratch/grp/msc_appbio/Group17_ABCC/scripts/sra_job%j.out
#SBATCH --job-name=sra_to_fastq
#SBATCH --nodes=1
#SBATCH --ntasks=1
#SBATCH --time=01:00:00
#SBATCH --partition=msc_appbio

module load sra-tools/3.0.3-gcc-13.2.0

echo "Start of SRA conversion to fastq"

mkdir -p /scratch/grp/msc_appbio/Group17_ABCC/fastq_files 

cd /scratch/grp/msc_appbio/Group17_ABCC/SRA_raw_data

fasterq-dump --split-files -O /scratch/grp/msc_appbio/Group17_ABCC/fastq_files *.sra

echo "End of fastq conversion"
```

## QC of the sequences

fastqc_job.sh
```{bash}
#!/bin/bash

#SBATCH --output=/scratch/grp/msc_appbio/Group17_ABBC/fastq_files/scripts/fastqc_job%j.out
#SBATCH --job-name=fastq_to_fastqc
#SBATCH --nodes=1
#SBATCH --ntasks=1
#SBATCH --time=01:00:00
#SBATCH --partition=msc_appbio


module load fastqc/0.11.9-gcc-13.2.0

echo "Start of fastqc"

cd /scratch/grp/msc_appbio/Group17_ABCC/fastq_files/

fastqc -o /scratch/grp/msc_appbio/Group17_ABCC/fastqc_report *.fastq

echo "End of fastqc"
```

## Trimming 

trimming.sh
```{bash}
#!/bin/bash

#SBATCH --output=/scratch/grp/msc_appbio/group17_ABCC/trimming_job_%j.out
#SBATCH --job-name=trimming
#SBATCH --time=01:00:00
#SBATCH --nodes=1

module load py-cutadapt/4.4-gcc-13.2.0-python-3.11.6

FASTQ_DIR=/scratch/grp/msc_appbio/Group17_ABCC/fastq_files

OUTPUT_DIR=/scratch/grp/msc_appbio/Group17_ABCC/trimmed
mkdir -p $OUTPUT_DIR

ADAPTER="AGATCGGAAGAGCACACGTCTGAACTCCAGTCA"

SAMPLES=(
SRR1166442
SRR1166443
SRR1166444
SRR1166445
SRR1166446
SRR1166447
)

for s in "${SAMPLES[@]}"; do
    if [[ ! -f "${FASTQ_DIR}/${s}.fastq" ]]; then
        echo "Warning: ${s}.fastq not found, skipping..."
        continue
    fi

    echo "Trimming adapters from $s.fastq..."
    cutadapt -a $ADAPTER -o ${OUTPUT_DIR}/${s}_trimmed.fastq ${FASTQ_DIR}/${s}.fastq --cores=4
    echo "Finished $s"
done

echo "All samples trimmed!"
```

## QC on these trimmed reads

trimmed_fastqc.sh
```{bash}
#!/bin/bash
#SBATCH --output=/scratch/grp/msc_appbio/group17_ABCC/trimmed_fastqc_%j.out
#SBATCH --job-name=trimmed_fastqc
#SBATCH --time=01:00:00
#SBATCH --nodes=1

module load fastqc/0.11.9-gcc-13.2.0

echo "start of fastqc"

cd /scratch/grp/msc_appbio/Group17_ABCC/trimmed

fastqc *_trimmed.fastq

echo "end of fastqc"
```

trimmed_multiqc.sh
```{bash}
#!/bin/bash
#SBATCH --output=/scratch/grp/msc_appbio/group17_ABCC/trimmed_multiqc_%j.out
#SBATCH --job-name=trimmed_multiqc
#SBATCH --time=01:00:00
#SBATCH --nodes=1

module load py-multiqc/1.15-gcc-13.2.0-python-3.11.6

echo "Running Multiqc on trimmed files"

TRIM_DIR=/scratch/grp/msc_appbio/group17_ABCC/trimmed

OUT_DIR=/scratch/grp/msc_appbio/group17_ABCC/trimmed_multiqc

mkdir -p /scratch/grp/msc_appbio/group17_ABCC/trimmed_multiqc

multiqc $TRIM_DIR -o $OUT_DIR

echo "MultiQC completed. Report saved to: $OUT_DIR"
```

------

## Manually annotating and combining our custom genome

Locally downloaded N. crassa β-glucosidase gh1-1 CDS in gh1_1.fasta, N. crassa cellodextrin transporter cdt-1 in cdt-1.fasta and eGFP sequence.
Then SCP to HPC in /scratch/grp/msc_appbio/Group17_ABCC/ref_genome


## Combine cdt1 and egfp together

cdt1_egfp.sh
```{bash}
#!/bin/bash

#SBATCH --output=/scratch/grp/msc_appbio/Group17_ABCC/ref_genome/cdt1_egfp_job%j.out
#SBATCH --job-name=make_cdt1_egfp
#SBATCH --nodes=1
#SBATCH --ntasks=1
#SBATCH --time=01:00:00
#SBATCH --partition=msc_appbio

echo "Start of cdt1_egfp fusion"

cd /scratch/grp/msc_appbio/Group17_ABCC/ref_genome/

# Step 1: remove stop codon from cdt1_CDS
sed '1d' cdt-1_CDS.fasta | tr -d '\n' | sed 's/...$//' > cdt1_noSTOP.fasta

# Step 2: convert sequences to one-line format
grep -v "^>" cdt1_noSTOP.seq | tr -d '\n' > cdt1.fast
grep -v "^>" EGFP_CDS.fasta   | tr -d '\n' > egfp.fasta

# Step 3: create the fused cdt1_egfp FASTA
echo ">cdt1_egfp" > cdt1_egfp.fasta
cat cdt1.seq egfp.seq >> cdt1_egfp.fasta

echo "End of cdt1_egfp fusion"
```

## Manually combining the reference genome, gh1_1, cdt_1 egfp into one fasta

combined_genome.sh
```{bash}
#!/bin/bash

#SBATCH --output=/scratch/grp/msc_appbio/Group17_ABCC/ref_genome/combined_ref_job%j.out
#SBATCH --job-name=make_combined_ref
#SBATCH --nodes=1
#SBATCH --ntasks=1
#SBATCH --time=00:30:00
#SBATCH --partition=msc_appbio

echo "Start combining genome"

cd /scratch/grp/msc_appbio/Group17_ABCC/ref_genome

cat yeast_reference_genome.fna \
    gh1_1_CDS.fasta \
    cdt1_egfp.fasta \
    > custom_combined_genome.fasta

echo "Done combining genome"
```

## Checking the genome size 

genome_size.sh 
```{bash}
#!/bin/bash
#SBATCH --output=/scratch/grp/msc_appbio/Group17_ABCC/ref_genome/genome_size_job%j.out
#SBATCH --job-name=genome_size
#SBATCH --nodes=1
#SBATCH --ntasks=1
#SBATCH --time=00:05:00
#SBATCH --partition=msc_appbio

echo "Checking genome size..."

cd /scratch/grp/msc_appbio/Group17_ABCC/ref_genome/

# Count total base pairs (no headers)
bp=$(grep -v "^>" combined_yeast_ref_genome.fasta | tr -d '\n' | wc -c)

echo "Total base pairs (bp): $bp"

# Convert to megabases (Mb) manually — printed in one line
echo "Genome size in Mb: $(echo "$bp / 1000000" | bc -l)"

echo "Done."
```

# Manually annotate the genes 
gtf_custom_genes.sh
```{bash}
#!/bin/bash
#SBATCH --output=/scratch/grp/msc_appbio/Group17_ABCC/ref_genome/gtf_custom_genes_job%j.out
#SBATCH --job-name=gtf_custom_genes
#SBATCH --nodes=1
#SBATCH --ntasks=1
#SBATCH --time=00:05:00
#SBATCH --partition=msc_appbio

echo "Adding custom genes to GTF..."

cd /scratch/grp/msc_appbio/Group17_ABCC/ref_genome/

# Get sequence lengths from FASTA
gh1_len=$(grep -A 100000 -m 1 ">gh1_1_CDS" custom_combined_genome.fasta | tail -n +2 | tr -d '\n' | wc -c)
cdt1_len=$(grep -A 100000 -m 1 ">cdt1_egfp" custom_combined_genome.fasta | tail -n +2 | tr -d '\n' | wc -c)

echo "gh1_1_CDS length (bp): $gh1_len"
echo "cdt1_egfp length (bp): $cdt1_len"

cat <<EOF >> gene_annotation_yeast.gtf
gh1_1_CDS       custom  gene    1       $gh1_len        .       +       .           gene_id "gh1_1_CDS";
gh1_1_CDS       custom  transcript      1       $gh1_len        .       +           .       gene_id "gh1_1_CDS"; transcript_id "gh1_1_CDS.t1";
gh1_1_CDS       custom  exon    1       $gh1_len        .       +       .           gene_id "gh1_1_CDS"; transcript_id "gh1_1_CDS.t1"; exon_number "1";

cdt1_egfp       custom  gene    1       $cdt1_len       .       +       .           gene_id "cdt1_egfp";
cdt1_egfp       custom  transcript      1       $cdt1_len       .       +           .       gene_id "cdt1_egfp"; transcript_id "cdt1_egfp.t1";
cdt1_egfp       custom  exon    1       $cdt1_len       .       +       .           gene_id "cdt1_egfp"; transcript_id "cdt1_egfp.t1"; exon_number "1";
EOF

echo "Custom genes successfully added to gtf."
```


------

## Indexing with STAR

indexing.sh
```{bash}
#!/bin/bash
#SBATCH --job-name=star_index_custom
#SBATCH --output=/scratch/grp/msc_appbio/Group17_ABCC/scripts/index_custom_%j.out
#SBATCH --time=03:00:00
#SBATCH --nodes=1
#SBATCH --ntasks=4
#SBATCH --partition=msc_appbio

module load star/2.7.10b-gcc-13.2.0

indexdir=/scratch/grp/msc_appbio/Group17_ABCC/star_index
FASTA=/scratch/grp/msc_appbio/Group17_ABCC/ref_genome/custom_combined_genome.fasta
GTF=/scratch/grp/msc_appbio/Group17_ABCC/ref_genome/custom_combined_annotation.gtf

mkdir -p $indexdir

echo "Start of star indexing"

STAR \
    --runMode genomeGenerate \
    --runThreadN 4 \
    --genomeDir $indexdir \
    --genomeFastaFiles $FASTA \
    --sjdbGTFfile $GTF \
    --sjdbOverhang 49   
    
echo "End of star indexing"
```

------

## Alignment with STAR

alignment.sh
```{bash}
#SBATCH --output=/scratch/grp/msc_appbio/Group17_ABCC/scripts/star_clean_align_%j.out
#SBATCH --time=08:00:00
#SBATCH --nodes=1
#SBATCH --ntasks=4
#SBATCH --partition=msc_appbio

module load seqtk/1.4-gcc-13.2.0
module load star/2.7.10b-gcc-13.2.0
module load samtools/1.17-gcc-13.2.0-python-3.11.6

# Directories
trim_dir=/scratch/grp/msc_appbio/Group17_ABCC/trimmed
clean_trim_dir=/scratch/grp/msc_appbio/Group17_ABCC/trimmed_cleaned
alignment_dir=/scratch/grp/msc_appbio/Group17_ABCC/alignment_star
index_dir=/scratch/grp/msc_appbio/Group17_ABCC/star_index

mkdir -p $clean_trim_dir
mkdir -p $alignment_dir

echo "Start of cleaning the trimmed and alignment"

# Loop for all 6 files 
for f in $trim_dir/*_trimmed.fastq; do
    sample=$(basename $f _trimmed.fastq)

    # 1. Clean the trimmed reads
    clean_FASTQ=$clean_trim_dir/${sample}_trimmed_clean.fastq
    echo "Cleaning $f "
    seqtk seq -L 1 $f > $clean_FASTQ

    # 2. Alignment on the cleaned trimmed reads
    echo "Aligning $clean_FASTQ "
    STAR \
        --runThreadN 4 \
        --genomeDir $index_dir \
        --readFilesIn $clean_FASTQ \
        --outFileNamePrefix $alignment_dir/${sample}_ \
        --outSAMtype BAM SortedByCoordinate
done

echo "End of cleaning the trimmed and alignment"

```

------

#Generating Count Data with featureCounts
gene_counts.sh

```{r}
#!/bin/bash
#SBATCH --output=/scratch/grp/msc_appbio/Group17_ABCC/alignment_star/featureCounts_job%j.out
#SBATCH --job-name=gene_counts
#SBATCH --nodes=1
#SBATCH --ntasks=1
#SBATCH --cpus-per-task=4
#SBATCH --time=01:00:00
#SBATCH --partition=msc_appbio

# Load Subread (featureCounts)
module load subread/2.0.2-gcc-13.2.0

echo "Starting gene counting with featureCounts"

# Move to alignment directory
cd /scratch/grp/msc_appbio/Group17_ABCC/alignment_star

# Run featureCounts correctly
featureCounts \
  -a /scratch/grp/msc_appbio/Group17_ABCC/ref_genome/custom_combined_annotation.gtf \
  -o gene_counts.txt \
  *.bam

echo "featureCounts gene counting finished."
```

------
#R
With the count table, gene_counts.txt was downloaded locally from the HPC to work with in R.

#Differential Expression Analysis with DESeq2

```{r}

library(data.table)
library(DESeq2)

# Set base directory 
setwd("C:/Users/sarah/OneDrive/Desktop/KCL/APCC/Group") 

# Import the data from local
data <- fread("C:/Users/sarah/Downloads/gene_counts.txt", header = TRUE)

# Create a numeric matrix with the load counts
counts <- as.matrix(data[, 7:12, with=FALSE])
rownames(counts) <- data$Geneid

grown_condition <- factor(c("glucose", "glucose","glucose", "cellobiose", "cellobiose", "cellobiose"))
col_data<- data.frame(row.names = colnames(counts), grown_condition)

#Create the DESeqDataSet object
data <- DESeqDataSetFromMatrix(
    countData = counts, 
    colData = col_data,
    design = ~ grown_condition 
)

# DESeq 
data <- DESeq(data)
results_deseq <- results(data, contrast = c("grown_condition", "cellobiose", "glucose"))

# Save as a csv
write.csv(results_deseq, file = "DESEQ_results.csv", row.names = FALSE)

# Normalised counts
norm_counts <- counts(data, normalized = TRUE)

# Save as a csv 
write.csv(norm_counts, file = "normalised_counts.csv", row.names = TRUE)

```


# Significant Genes 
Calculate the number of differentially expressed genes
```{r}
library(dplyr)

results_df <- as.data.frame(results_deseq)
results_df <- na.omit(results_df) # remove NAs if there are

FDR_CUTOFF <- 0.001 # Define our cutoff for FDR
LOG2FC_CUTOFF <- 1.0 # Define our log2 2-fold change cutoff

#Significant genes
sig_genes <- results_df[which(results_df$padj < FDR_CUTOFF & abs(results_df$log2FoldChange) >= LOG2FC_CUTOFF), ]

# Number of differentially expressed genes
num_sig <- nrow(sig_genes)

# Sae as a csv
write.csv(sig_genes, file="Significant_Genes.csv", row.names = TRUE)
```



# Volcano Plot
```{r}
library(ggplot2)

# Create our Y axis with -log10 padj
results_df$log10Padj <- -log10(results_df$padj)

# Using the cutoffs for colouring on graph
results_df <- results_df %>%
  mutate(DiffExpression = case_when(
    log2FoldChange >= LOG2FC_CUTOFF & padj <= FDR_CUTOFF ~ "Upregulated",
    log2FoldChange <= -LOG2FC_CUTOFF & padj <= FDR_CUTOFF ~ "Downregulated",
    TRUE ~ "Not Significant"
  ))

# Creating our volcano plot
volcano_plot <- ggplot(results_df, 
                       aes(x = log2FoldChange, 
                           y = log10Padj, 
                           color = DiffExpression)) +
  geom_point(size = 1, alpha = 0.7) +
  scale_color_manual(values = c("Upregulated" = "red", #significant 
                                "Downregulated" = "red", 
                                "Not Significant" = "black")) +

  geom_hline(yintercept = -log10(FDR_CUTOFF), # line for FDR cutoff
             linetype = "dashed", 
             color = "grey") +
  geom_vline(xintercept = c(-LOG2FC_CUTOFF, LOG2FC_CUTOFF), 
             linetype = "dashed", # line for log2 cutoff
             color = "grey") +
  
  labs(
    title = "Volcano Plot",
    subtitle = paste(num_sig, "Differentially Expressed Genes"),
    x = expression("log2 Fold Change (Cellobiose/Glucose) with DESeq"),
    y = expression("-log10 Adjusted P-value")
  ) +
  
  theme_minimal() +
  theme(legend.title = element_blank())

print(volcano_plot)

# Save the plot
ggsave("Volcano_Plot.png", plot = volcano_plot, width = 7, height = 7, units = "in")
```

#RPKM Calculation
```{r}
gene_length_bp <- gcdata$Length
gene_length_kb <- gene_length_bp / 1000

raw_counts<- counts(data, normalized=FALSE)
# Total reads per library
total_counts <- colSums(raw_counts)

# Divide counts by gene length (kb)
rpkm <- sweep(counts, 1, gene_length_kb, FUN="/")
# Divide by library totals (per million)
rpkm <- sweep(rpkm, 2, total_counts/1e6, FUN="/")

# log2 for visualization
log2_rpkm <- log2(rpkm + 1)
write.csv(log2_rpkm, file="log2_rpkm_normalised.csv", row.names=TRUE)

```



